{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modular_code_custom_cnn_1.0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkbond777/DTI-meta-learning/blob/master/Modular_code_custom_cnn_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lizB664-qv_j"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Ywxg6aqSI8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGCXfYtu3u2X"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "\n",
        "import re\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from shutil import copyfile\n",
        "\n",
        "import datetime\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import time\n",
        "\n",
        "import glob\n",
        "\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJmbueu3qp1G"
      },
      "source": [
        "#chembl_id = 'CHEMBL286'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o0fDyOtAxyU"
      },
      "source": [
        "#! rm -r /content/model_init_CHEMBL286"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_zHF5NJ0reB"
      },
      "source": [
        "def main(src_df, target_ids,metrics):\n",
        "\n",
        "  curr_dt_time = datetime.datetime.now()\n",
        "\n",
        "  # unzipping entire image data \n",
        "  src_img_path = '/content/drive/MyDrive/ML-DTI/target_training_datasets.zip'\n",
        "  dest_img_path = '/content/img_path'\n",
        "  if not os.path.exists(dest_img_path):\n",
        "    os.mkdir(dest_img_path) \n",
        "    unzip_img_data(src_img_path,dest_img_path)\n",
        "\n",
        "  out_file = '/content/drive/MyDrive/ML-DTI/metrics_' + 'custom' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '.csv'\n",
        "\n",
        "  for target in target_ids:\n",
        "    target_df = target_specific_data(src_df,target)\n",
        "    target_df.reset_index(drop=True,inplace=True)\n",
        "    target_df['labels'] = target_df['labels'].astype(str)\n",
        "    target_specific_run(target_df, target, out_file, metrics)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttmfEe-CJV1z"
      },
      "source": [
        "def target_specific_run(target_df, target_id, filename,metrics):\n",
        "\n",
        "  # imagedatagenerator for CNN\n",
        "  train_generator, valid_generator, test_generator = prepare_train_valid_test_cnn_data(target_df, target_id)\n",
        "\n",
        "  cnn_model = custom_cnn_model()\n",
        "\n",
        "  cnn_model = compile_cnn_model(cnn_model, metrics)\n",
        "\n",
        "  cl = callback_list(cnn_model, metrics, target_id)\n",
        "\n",
        "  cnn_model, history = cnn_model_training(50, cnn_model, train_generator, valid_generator, cl)\n",
        "\n",
        "  model_weights = get_latest_file(target_id)\n",
        "\n",
        "\n",
        "  cnn_model = load_weights(cnn_model, model_weights)\n",
        "\n",
        "  train_metrics = log_metrics(cnn_model, train_generator)\n",
        "\n",
        "  test_metrics = log_metrics(cnn_model, test_generator)\n",
        "\n",
        "  cnn_predict_df = predictions(cnn_model, target_df, target_id)\n",
        "\n",
        "  encoded_df = label_encoding_smiles(target_df)\n",
        "\n",
        "  svm_cnn_acc,svm_cnn_auc,svm_cnn_f1_score = svm_model_training(encoded_df, cnn_predict_df, metrics, with_cnn = True)\n",
        "\n",
        "  l = [target_id,train_metrics[1],train_metrics[2],train_metrics[3][0],test_metrics[1],test_metrics[2],test_metrics[3][0],svm_cnn_acc,svm_cnn_auc,svm_cnn_f1_score]\n",
        "\n",
        "  data = \",\".join([str(i) for i in l])\n",
        "  \n",
        "  with open(filename, \"a\") as myfile:\n",
        "    myfile.write(data + \"\\n\")\n",
        "\n",
        "  delete_folder(target_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290PFGRJadxm"
      },
      "source": [
        "def delete_folder(target_id):\n",
        "  folder_name = 'model_init' + '_' + target_id + '/'\n",
        "  !rm -r {folder_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XelgmSY-Ak8A"
      },
      "source": [
        "def svm_model_training(encoded_df, cnn_predict_df, metrics, with_cnn = False):\n",
        "  svm_train_df = prepare_svm_data(encoded_df[encoded_df['type'] != 'test'], cnn_predict_df, with_cnn)\n",
        "\n",
        "  svm_test_df = prepare_svm_data(encoded_df[encoded_df['type'] == 'test'], cnn_predict_df, with_cnn)\n",
        "\n",
        "  model_svm = train_svm(svm_train_df)\n",
        "\n",
        "  return test_svm(model_svm, svm_test_df, metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqqgIIbR1wgy"
      },
      "source": [
        "def get_latest_file(target_id):\n",
        "  folder_path = 'model_init' + '_' + target_id + '/*'\n",
        "  list_of_files = glob.glob(folder_path) # * means all if need specific format then *.csv\n",
        "  latest_file = max(list_of_files, key=os.path.getctime)\n",
        "  return latest_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUgxeeKpitNp"
      },
      "source": [
        "def unzip_img_data(src_path,dest_path):\n",
        "  if dest_path is None:\n",
        "    !unzip -qq {src_path}\n",
        "  else:\n",
        "    !unzip -qq {src_path} -d {dest_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOfG5Ib4kZkS"
      },
      "source": [
        "def prepare_data():\n",
        "\n",
        "  # create a column for img path\n",
        "  def f(row):\n",
        "    return row['drug_id'] + '.png'\n",
        "\n",
        "  # read json files containing test, train and valid\n",
        "  json_df = pd.read_csv('/content/drive/MyDrive/ML-DTI/json_df.csv')\n",
        "  \n",
        "  # read smiles files\n",
        "  smiles_df = pd.read_csv('/content/drive/MyDrive/ML-DTI/chembl_v28_json_joined_202110241711.csv')\n",
        "\n",
        "  final_df = pd.merge(json_df, smiles_df, left_on=['drug_id',], right_on=['drug_id'],how='inner')\n",
        "\n",
        "  final_df['img_path'] = final_df.apply(f, axis=1)\n",
        "\n",
        "  return final_df\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsXoDQfUk1D-"
      },
      "source": [
        "def target_specific_data(df, target_id):\n",
        "  # filter data based on given chembl_id\n",
        "  return df[df['target_id'] == target_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50XAHpGIlIq-"
      },
      "source": [
        "def prepare_train_valid_test_cnn_data(df, target_id, img_h = 200, img_w = 200):\n",
        "  \n",
        "  print(target_id + '\\n')\n",
        "  \n",
        "  zip_path = '/content/img_path/' + target_id + '.zip'\n",
        "  img_path = '/content/img_path/' + target_id + '/imgs/'\n",
        "\n",
        "\n",
        "  if not os.path.exists(img_path): \n",
        "    unzip_img_data(zip_path,'/content/img_path/')\n",
        "\n",
        "  datagen=ImageDataGenerator(validation_split=0.2)\n",
        "\n",
        "  train_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=df[df['type'] != 'test'],\n",
        "    directory=img_path,\n",
        "    x_col=\"img_path\",\n",
        "    y_col=\"labels\",\n",
        "    subset=\"training\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(img_h,img_w))\n",
        "  \n",
        "  valid_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=df[df['type'] != 'test'],\n",
        "    directory=img_path,\n",
        "    x_col=\"img_path\",\n",
        "    y_col=\"labels\",\n",
        "    subset=\"validation\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(img_h,img_w))\n",
        "  \n",
        "  test_datagen=ImageDataGenerator()\n",
        "  \n",
        "  test_generator=test_datagen.flow_from_dataframe(\n",
        "    dataframe=df[df['type'] == 'test'],\n",
        "    directory=img_path,\n",
        "    x_col=\"img_path\",\n",
        "    y_col=\"labels\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(img_h,img_w))\n",
        "  \n",
        "  return train_generator, valid_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaS1IVoclIlG"
      },
      "source": [
        "# def pre_trained_cnn_model(name, img_height=200,img_width=200):\n",
        "#   # Configure the dataset for performance\n",
        "#   #AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "#   #train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "#   # train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "#   # val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "#   preprocess_input, base_model = pre_trained_cnn_model_selection(name)\n",
        "  \n",
        "#   global_average_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
        "\n",
        "#   prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "#   base_model.trainable = False\n",
        "\n",
        "#   inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#   x = preprocess_input(inputs)\n",
        "#   x = base_model(x, training=False)\n",
        "#   x = global_average_layer(x)\n",
        "#   x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "#   outputs = prediction_layer(x)\n",
        "#   model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "#   return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-7KI6eEeRql"
      },
      "source": [
        "def custom_cnn_model(img_height=200,img_width=200):\n",
        "    model = Sequential([\n",
        "      layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "      layers.MaxPooling2D(),\n",
        "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "      layers.MaxPooling2D(),\n",
        "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "      layers.MaxPooling2D(),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8lSegABravD"
      },
      "source": [
        "# def pre_trained_cnn_model_selection(name, img_height=200,img_width=200):\n",
        "\n",
        "#   if 'vgg16' in name.lower():\n",
        "#     preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
        "\n",
        "#     base_model = tf.keras.applications.vgg16.VGG16(input_shape=(img_height, img_width, 3),\n",
        "#                                                   include_top=False,\n",
        "#                                                   weights='imagenet')\n",
        "#     return preprocess_input, base_model\n",
        "    \n",
        "#   if 'inception' in name.lower():\n",
        "#     preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "#     base_model = tf.keras.applications.inception_v3.InceptionV3(input_shape=(img_height, img_width, 3),\n",
        "#                                                   include_top=False,\n",
        "#                                                   weights='imagenet')\n",
        "#     return preprocess_input, base_model\n",
        "\n",
        "\n",
        "    \n",
        "#   preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "#   base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(img_height, img_width, 3),\n",
        "#                                               include_top=False,\n",
        "#                                               weights='imagenet')\n",
        "  \n",
        "#   return preprocess_input, base_model\n",
        "    \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lFAuVB6WJVK"
      },
      "source": [
        "def compile_cnn_model(model, metric_list, base_rate = 0.0001):\n",
        "  metrics = get_metrics(metric_list)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=metrics)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9yoyxGMDsk6"
      },
      "source": [
        "def get_metrics(metric_list):\n",
        "  metric_list_lower = [i.lower() for i in metric_list]\n",
        "  metrics = []\n",
        "  if 'accuracy' in metric_list_lower :\n",
        "    metrics.append('accuracy')\n",
        "  if 'auc' in metric_list_lower :\n",
        "    metrics.append(tf.keras.metrics.AUC(name='auc'))\n",
        "  if 'f1_score' in metric_list_lower:\n",
        "    metrics.append(tfa.metrics.F1Score(num_classes=1,threshold=0.5,\n",
        "                                       name='f1_score'))\n",
        "  \n",
        "  return metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B39qC844lIik"
      },
      "source": [
        "def callback_list(model, metric_list, target_id):\n",
        "\n",
        "  metric_list_1st = metric_list[0].lower()\n",
        "\n",
        "  model_name = 'model_init' + '_' + target_id + '/'\n",
        "\n",
        "  if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "  filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{auc:.5f}-{val_loss:.5f}-{val_auc:.5f}.h5'\n",
        "\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n",
        "                                                  monitor='val_auc', \n",
        "                                                  verbose=1, \n",
        "                                                  save_best_only=True, \n",
        "                                                  save_weights_only=True, \n",
        "                                                  mode='max', \n",
        "                                                  save_freq='epoch')\n",
        "\n",
        "  es = tf.keras.callbacks.EarlyStopping(monitor='val_auc',\n",
        "                                        mode='max', \n",
        "                                        verbose=1, \n",
        "                                        patience=5)\n",
        "  #callbacks_list = [checkpoint, LR, es]\n",
        "  callbacks_list = [checkpoint, es]\n",
        "\n",
        "  return callbacks_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBDThr5NlIfm"
      },
      "source": [
        "def cnn_model_training(epoch, model, train_ds, val_ds, callbacks_list):\n",
        "\n",
        "  history = model.fit(train_ds,\n",
        "                      epochs=epoch,\n",
        "                      validation_data=val_ds,\n",
        "                      callbacks=callbacks_list)\n",
        "  return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzmrdsAXlvMv"
      },
      "source": [
        "def load_weights(model, model_weights):\n",
        "  model.load_weights(model_weights)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqgDL69hlvJ6"
      },
      "source": [
        "def log_metrics(model, ds):\n",
        "  return model.evaluate(ds, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTSQ9Xk4dG86"
      },
      "source": [
        "def predictions(model, df, target_id, img_height=200,img_width=200):\n",
        "  data_list = []\n",
        "  imgs_path = '/content/img_path/' + target_id + '/imgs/'\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    img_path = os.path.join(imgs_path, row['img_path'])\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "    #img_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(img_batch)\n",
        "    prediction = model.predict(img_batch)\n",
        "    data_list.append((row['drug_id'],row['labels'],prediction[0][0]))\n",
        "\n",
        "  df = pd.DataFrame(data_list,columns=['drug_id','label','y_pred_prob',])  \n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNfzuZIGyMCV"
      },
      "source": [
        "def label_encoding_smiles(df):\n",
        "\n",
        "  CHARCANSMISET = { \"#\": 1, \"%\": 2, \")\": 3, \"(\": 4, \"+\": 5, \"-\": 6, \n",
        "         \".\": 7, \"1\": 8, \"0\": 9, \"3\": 10, \"2\": 11, \"5\": 12, \n",
        "         \"4\": 13, \"7\": 14, \"6\": 15, \"9\": 16, \"8\": 17, \"=\": 18, \n",
        "         \"A\": 19, \"C\": 20, \"B\": 21, \"E\": 22, \"D\": 23, \"G\": 24,\n",
        "         \"F\": 25, \"I\": 26, \"H\": 27, \"K\": 28, \"M\": 29, \"L\": 30, \n",
        "         \"O\": 31, \"N\": 32, \"P\": 33, \"S\": 34, \"R\": 35, \"U\": 36, \n",
        "         \"T\": 37, \"W\": 38, \"V\": 39, \"Y\": 40, \"[\": 41, \"Z\": 42, \n",
        "         \"]\": 43, \"_\": 44, \"a\": 45, \"c\": 46, \"b\": 47, \"e\": 48, \n",
        "         \"d\": 49, \"g\": 50, \"f\": 51, \"i\": 52, \"h\": 53, \"m\": 54, \n",
        "         \"l\": 55, \"o\": 56, \"n\": 57, \"s\": 58, \"r\": 59, \"u\": 60,\n",
        "         \"t\": 61, \"y\": 62, \"/\" : 63, \"\\\\\" : 64, \"@\":65}\n",
        "\n",
        "  CHARCANSMILEN = 65\n",
        "\n",
        "  def one_hot_sequence(line, MAX_SEQ_LEN = 80, smi_ch_ind = CHARCANSMISET):\n",
        "    X = np.zeros((MAX_SEQ_LEN, len(smi_ch_ind))) \n",
        "    for i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
        "        X[i,(smi_ch_ind[ch])-1] = 1\n",
        "\n",
        "    return X.flatten() #.tolist()\n",
        "\n",
        "  df['lbl_encoding'] = df.apply(\n",
        "      lambda row : one_hot_sequence(row['canonical_smiles']), axis = 1)\n",
        "\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KFqJxgcfy14"
      },
      "source": [
        "def prepare_svm_data(df, cnn_predict_df,meta_learning=False):\n",
        "\n",
        "  df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "  def f(row):\n",
        "    if row['y_pred_prob'] <= 0.5 :\n",
        "        val = 0\n",
        "    else:\n",
        "        val = 1\n",
        "    return val\n",
        "\n",
        "  def svm_cnn_date(df, cnn_predict_df):\n",
        "    cnn_predict_df['y_pred'] = cnn_predict_df.apply(f,axis=1)\n",
        "    return pd.merge(df, cnn_predict_df, left_on=['drug_id',], \n",
        "                          right_on=['drug_id'],how='inner')\n",
        "    \n",
        "  if meta_learning:\n",
        "    final_svm_df = svm_cnn_date(df, cnn_predict_df)\n",
        "    final_svm_df = pd.concat([pd.DataFrame(final_svm_df.lbl_encoding.values.tolist()), final_svm_df.y_pred, final_svm_df.labels],axis=1)\n",
        "  else:\n",
        "    final_svm_df = pd.concat([pd.DataFrame(df.lbl_encoding.values.tolist()), df.labels],axis=1)\n",
        "  \n",
        "  final_svm_df = final_svm_df.astype('uint8')\n",
        "\n",
        "  return final_svm_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZg7yL_pyL9Y"
      },
      "source": [
        "def train_svm(svm_df, kernel_type = 'rbf'):\n",
        "  X_train = svm_df.drop(\"labels\", axis = 1)\n",
        "  y_train = svm_df['labels']\n",
        "\n",
        "  model = SVC(kernel=kernel_type, probability=True)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3whGJIewyL6c"
      },
      "source": [
        "def test_svm(model, svm_df_test, metrics):\n",
        "  X_test = svm_df_test.drop(\"labels\", axis = 1)\n",
        "  y_test = svm_df_test['labels']\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  accuracy = round(accuracy_score(y_test,y_pred),2)\n",
        "  roc_auc = round(roc_auc_score(y_test,y_pred),2) \n",
        "  pred_f1_score = round(f1_score(y_test,y_pred),2)\n",
        "  return accuracy, roc_auc, pred_f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0RHmbwuXUTO"
      },
      "source": [
        "### Preparing data and running model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxvOfVdoyL3U"
      },
      "source": [
        "src_df = prepare_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIhzixSkXDGs"
      },
      "source": [
        "l = ['CHEMBL223','CHEMBL3473','CHEMBL228','CHEMBL276','CHEMBL3568','CHEMBL1900','CHEMBL4822','CHEMBL1981','CHEMBL2069','CHEMBL3024','CHEMBL3231','CHEMBL2959','CHEMBL2742','CHEMBL1908389','CHEMBL4578','CHEMBL1785','CHEMBL1994','CHEMBL3286','CHEMBL4128','CHEMBL206','CHEMBL4308','CHEMBL257','CHEMBL2993','CHEMBL2039','CHEMBL2292','CHEMBL208','CHEMBL2581','CHEMBL1855','CHEMBL2028','CHEMBL6136','CHEMBL2413','CHEMBL3571','CHEMBL2722','CHEMBL2695','CHEMBL298','CHEMBL1821','CHEMBL213','CHEMBL2014','CHEMBL304','CHEMBL2001','CHEMBL3522','CHEMBL2949','CHEMBL1946','CHEMBL5147','CHEMBL3974','CHEMBL3920','CHEMBL1867','CHEMBL288','CHEMBL2016','CHEMBL3973','CHEMBL2598','CHEMBL3358','CHEMBL1835','CHEMBL1978','CHEMBL4588','CHEMBL216','CHEMBL2431','CHEMBL281','CHEMBL3553','CHEMBL1875','CHEMBL4204','CHEMBL2808','CHEMBL229','CHEMBL1936','CHEMBL331','CHEMBL3594','CHEMBL4794','CHEMBL2820','CHEMBL338','CHEMBL3045','CHEMBL2525','CHEMBL6164','CHEMBL3142','CHEMBL3649','CHEMBL5407','CHEMBL2035','CHEMBL1991','CHEMBL4908','CHEMBL2208','CHEMBL221','CHEMBL321','CHEMBL4422','CHEMBL3979','CHEMBL265','CHEMBL3976','CHEMBL3869','CHEMBL2047','CHEMBL335','CHEMBL2276','CHEMBL324','CHEMBL1801','CHEMBL231','CHEMBL308','CHEMBL3629','CHEMBL313']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W-4_PskixVk"
      },
      "source": [
        "len(target_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pfMdTeL_1TA"
      },
      "source": [
        "metrics = ['accuracy','auc','f1_score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzrVd2RXQLA",
        "collapsed": true
      },
      "source": [
        "start_time = time.time()\n",
        "main(src_df, target_ids,metrics)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWsECJu_gt5V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}