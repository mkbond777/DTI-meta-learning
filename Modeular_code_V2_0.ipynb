{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeular_code_V2_0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkbond777/DTI-meta-learning/blob/master/Modeular_code_V2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lizB664-qv_j"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Ywxg6aqSI8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGCXfYtu3u2X"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "\n",
        "import re\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from shutil import copyfile\n",
        "\n",
        "import datetime\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import time\n",
        "\n",
        "import glob\n",
        "\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJmbueu3qp1G"
      },
      "source": [
        "#chembl_id = 'CHEMBL286'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o0fDyOtAxyU"
      },
      "source": [
        "#! rm -r /content/model_init_CHEMBL286"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_zHF5NJ0reB"
      },
      "source": [
        "def main(src_df, target_ids,cnn_model_name,metrics):\n",
        "\n",
        "  curr_dt_time = datetime.datetime.now()\n",
        "\n",
        "  # unzipping entire image data \n",
        "  src_img_path = '/content/drive/MyDrive/ML-DTI/target_training_datasets.zip'\n",
        "  dest_img_path = '/content/img_path'\n",
        "  if not os.path.exists(dest_img_path):\n",
        "    os.mkdir(dest_img_path) \n",
        "    unzip_img_data(src_img_path,dest_img_path)\n",
        "\n",
        "  # prepare data\n",
        "  #src_df = prepare_data()\n",
        "\n",
        "  # # target_ids\n",
        "  #target_ids = src_df['target_id'].tolist()\n",
        "\n",
        "  #target_ids = ['CHEMBL3969','CHEMBL2035']\n",
        "\n",
        "  out_file = '/content/drive/MyDrive/ML-DTI/metrics_' + cnn_model_name[0] + '_' + metrics[0] + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '.csv'\n",
        "\n",
        "  for target in target_ids:\n",
        "    target_df = target_specific_data(src_df,target)\n",
        "    target_df.reset_index(drop=True,inplace=True)\n",
        "    target_df['labels'] = target_df['labels'].astype(str)\n",
        "    target_specific_run(target_df, target, out_file,cnn_model_name, metrics)\n",
        "\n",
        "  # target_df = target_specific_data(src_df,'CHEMBL286')\n",
        "\n",
        "  # target_df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "  # target_df['labels'] = target_df['labels'].astype(str)\n",
        "\n",
        "  # target_specific_run(target_df, 'CHEMBL286')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttmfEe-CJV1z"
      },
      "source": [
        "def target_specific_run(target_df, target_id, filename,cnn_model_name,metrics):\n",
        "\n",
        "  # imagedatagenerator for CNN\n",
        "  train_generator, valid_generator, test_generator = prepare_train_valid_test_cnn_data(target_df, target_id)\n",
        "  #print('Train,Test data generated \\n')\n",
        "\n",
        "  # cnn model\n",
        "\n",
        "  cnn_model = pre_trained_cnn_model(cnn_model_name)\n",
        "\n",
        "  cnn_model = compile_cnn_model(cnn_model, metrics)\n",
        "\n",
        "  cl = callback_list(cnn_model, metrics, target_id)\n",
        "\n",
        "  cnn_model, history = cnn_model_training(50, cnn_model, train_generator, valid_generator, cl)\n",
        "\n",
        "  model_weights = get_latest_file(target_id)\n",
        "\n",
        "  #model_weights = '/content/model-00035-0.18334-0.97339-0.67943-0.90520.h5'\n",
        "\n",
        "  cnn_model = load_weights(cnn_model, model_weights)\n",
        "\n",
        "  train_metrics = log_metrics(cnn_model, train_generator)\n",
        "\n",
        "  test_metrics = log_metrics(cnn_model, test_generator)\n",
        "\n",
        "  cnn_predict_df = predictions(cnn_model, target_df, target_id)\n",
        "\n",
        "  encoded_df = label_encoding_smiles(target_df)\n",
        "\n",
        "  # svm_auc, svm_f1_score = svm_model_training(encoded_df, cnn_predict_df, with_cnn = False)\n",
        "\n",
        "  # svm_cnn_auc, svm_cnn_f1_score = svm_model_training(encoded_df, cnn_predict_df, with_cnn = True)\n",
        "\n",
        "  #l = [target_id,train_metrics[1],train_metrics[2][0],test_metrics[1],test_metrics[2][0],svm_auc,svm_f1_score,svm_cnn_auc,svm_cnn_f1_score]\n",
        "\n",
        "  #l = [target_id,train_metrics[1],train_metrics[2][0],test_metrics[1],test_metrics[2][0],svm_cnn_auc,svm_cnn_f1_score]\n",
        "\n",
        "  svm_acc = svm_model_training(encoded_df, cnn_predict_df, metrics, with_cnn = False)\n",
        "\n",
        "  svm_cnn_acc = svm_model_training(encoded_df, cnn_predict_df, metrics, with_cnn = True)\n",
        "\n",
        "  l = [target_id,train_metrics[1],test_metrics[1],svm_acc,svm_cnn_acc]\n",
        "\n",
        "  data = \",\".join([str(i) for i in l])\n",
        "  \n",
        "  with open(filename, \"a\") as myfile:\n",
        "    myfile.write(data + \"\\n\")\n",
        "\n",
        "  delete_folder(target_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290PFGRJadxm"
      },
      "source": [
        "def delete_folder(target_id):\n",
        "  folder_name = 'model_init' + '_' + target_id + '/'\n",
        "  !rm -r {folder_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XelgmSY-Ak8A"
      },
      "source": [
        "def svm_model_training(encoded_df, cnn_predict_df, metrics, with_cnn = False):\n",
        "  svm_train_df = prepare_svm_data(encoded_df[encoded_df['type'] != 'test'], cnn_predict_df, with_cnn)\n",
        "\n",
        "  svm_test_df = prepare_svm_data(encoded_df[encoded_df['type'] == 'test'], cnn_predict_df, with_cnn)\n",
        "\n",
        "  model_svm = train_svm(svm_train_df)\n",
        "\n",
        "  return test_svm(model_svm, svm_test_df, metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqqgIIbR1wgy"
      },
      "source": [
        "def get_latest_file(target_id):\n",
        "  folder_path = 'model_init' + '_' + target_id + '/*'\n",
        "  list_of_files = glob.glob(folder_path) # * means all if need specific format then *.csv\n",
        "  latest_file = max(list_of_files, key=os.path.getctime)\n",
        "  return latest_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUgxeeKpitNp"
      },
      "source": [
        "def unzip_img_data(src_path,dest_path):\n",
        "  if dest_path is None:\n",
        "    !unzip -qq {src_path}\n",
        "  else:\n",
        "    !unzip -qq {src_path} -d {dest_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOfG5Ib4kZkS"
      },
      "source": [
        "def prepare_data():\n",
        "\n",
        "  # create a column for img path\n",
        "  def f(row):\n",
        "    return row['drug_id'] + '.png'\n",
        "\n",
        "  # read json files containing test, train and valid\n",
        "  json_df = pd.read_csv('/content/drive/MyDrive/ML-DTI/json_df.csv')\n",
        "  \n",
        "  # read smiles files\n",
        "  smiles_df = pd.read_csv('/content/drive/MyDrive/ML-DTI/chembl_v28_json_joined_202110241711.csv')\n",
        "\n",
        "  final_df = pd.merge(json_df, smiles_df, left_on=['drug_id',], right_on=['drug_id'],how='inner')\n",
        "\n",
        "  final_df['img_path'] = final_df.apply(f, axis=1)\n",
        "\n",
        "  return final_df\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsXoDQfUk1D-"
      },
      "source": [
        "def target_specific_data(df, target_id):\n",
        "  # filter data based on given chembl_id\n",
        "  return df[df['target_id'] == target_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50XAHpGIlIq-"
      },
      "source": [
        "def prepare_train_valid_test_cnn_data(df, target_id, img_h = 200, img_w = 200):\n",
        "  \n",
        "  print(target_id + '\\n')\n",
        "  \n",
        "  zip_path = '/content/img_path/' + target_id + '.zip'\n",
        "  img_path = '/content/img_path/' + target_id + '/imgs/'\n",
        "\n",
        "\n",
        "  if not os.path.exists(img_path): \n",
        "    unzip_img_data(zip_path,'/content/img_path/')\n",
        "\n",
        "  datagen=ImageDataGenerator(validation_split=0.2)\n",
        "\n",
        "  train_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=df[df['type'] != 'test'],\n",
        "    directory=img_path,\n",
        "    x_col=\"img_path\",\n",
        "    y_col=\"labels\",\n",
        "    subset=\"training\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(img_h,img_w))\n",
        "  \n",
        "  valid_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=df[df['type'] != 'test'],\n",
        "    directory=img_path,\n",
        "    x_col=\"img_path\",\n",
        "    y_col=\"labels\",\n",
        "    subset=\"validation\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(img_h,img_w))\n",
        "  \n",
        "  test_datagen=ImageDataGenerator()\n",
        "  \n",
        "  test_generator=test_datagen.flow_from_dataframe(\n",
        "    dataframe=df[df['type'] == 'test'],\n",
        "    directory=img_path,\n",
        "    x_col=\"img_path\",\n",
        "    y_col=\"labels\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(img_h,img_w))\n",
        "  \n",
        "  return train_generator, valid_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaS1IVoclIlG"
      },
      "source": [
        "def pre_trained_cnn_model(name, img_height=200,img_width=200):\n",
        "  # Configure the dataset for performance\n",
        "  #AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "  #train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "  # train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "  # val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  preprocess_input, base_model = pre_trained_cnn_model_selection(name)\n",
        "  \n",
        "  global_average_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
        "\n",
        "  prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = preprocess_input(inputs)\n",
        "  x = base_model(x, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  outputs = prediction_layer(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8lSegABravD"
      },
      "source": [
        "def pre_trained_cnn_model_selection(name, img_height=200,img_width=200):\n",
        "\n",
        "  if 'vgg16' in name.lower():\n",
        "    preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
        "\n",
        "    base_model = tf.keras.applications.vgg16.VGG16(input_shape=(img_height, img_width, 3),\n",
        "                                                  include_top=False,\n",
        "                                                  weights='imagenet')\n",
        "    return preprocess_input, base_model\n",
        "    \n",
        "  if 'inception' in name.lower():\n",
        "    preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    base_model = tf.keras.applications.inception_v3.InceptionV3(input_shape=(img_height, img_width, 3),\n",
        "                                                  include_top=False,\n",
        "                                                  weights='imagenet')\n",
        "    return preprocess_input, base_model\n",
        "\n",
        "\n",
        "    \n",
        "  preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "  base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(img_height, img_width, 3),\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')\n",
        "  \n",
        "  return preprocess_input, base_model\n",
        "    \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lFAuVB6WJVK"
      },
      "source": [
        "def compile_cnn_model(model, metric_list, base_rate = 0.0001):\n",
        "  metrics = get_metrics(metric_list)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=metrics)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9yoyxGMDsk6"
      },
      "source": [
        "def get_metrics(metric_list):\n",
        "  metric_list_lower = [i.lower() for i in metric_list]\n",
        "  metrics = []\n",
        "  if 'accuracy' in metric_list_lower :\n",
        "    metrics.append('accuracy')\n",
        "  if 'auc' in metric_list_lower :\n",
        "    metrics.append(tf.keras.metrics.AUC(name='auc'))\n",
        "  if 'f1_score' in metric_list_lower:\n",
        "    metrics.append(tfa.metrics.F1Score(num_classes=1,threshold=0.5,\n",
        "                                       name='f1_score'))\n",
        "  \n",
        "  return metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B39qC844lIik"
      },
      "source": [
        "def callback_list(model, metric_list, target_id):\n",
        "\n",
        "  metric_list_1st = metric_list[0].lower()\n",
        "\n",
        "  if 'f1_score' in metric_list_1st:\n",
        "    monitor_m = 'val_f1_score'\n",
        "  elif 'accuracy' in metric_list_1st:\n",
        "    monitor_m = 'val_accuracy'\n",
        "  else:\n",
        "    monitor_m = 'val_auc'\n",
        "\n",
        "  # create model save folder such that it can be read\n",
        "  model_name = 'model_init' + '_' + target_id + '/'\n",
        "\n",
        "  if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "  if 'accuracy' in metric_list_1st:\n",
        "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{accuracy:.5f}-{val_loss:.5f}-{val_accuracy:.5f}.h5'\n",
        "  else:\n",
        "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{auc:.5f}-{val_loss:.5f}-{val_auc:.5f}.h5'\n",
        "\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n",
        "                                                  monitor=monitor_m, \n",
        "                                                  verbose=1, \n",
        "                                                  save_best_only=True, \n",
        "                                                  save_weights_only=True, \n",
        "                                                  mode='max', \n",
        "                                                  save_freq='epoch')\n",
        "\n",
        "  #LR = ReduceLROnPlateau(monitor='val_auc', factor=0.4, verbose=1, patience=3) # write the REducelronplateau code here\n",
        "\n",
        "  es = tf.keras.callbacks.EarlyStopping(monitor=monitor_m,\n",
        "                                        mode='max', \n",
        "                                        verbose=1, \n",
        "                                        patience=5)\n",
        "  #callbacks_list = [checkpoint, LR, es]\n",
        "  callbacks_list = [checkpoint, es]\n",
        "\n",
        "  return callbacks_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBDThr5NlIfm"
      },
      "source": [
        "def cnn_model_training(epoch, model, train_ds, val_ds, callbacks_list):\n",
        "\n",
        "  history = model.fit(train_ds,\n",
        "                      epochs=epoch,\n",
        "                      validation_data=val_ds,\n",
        "                      callbacks=callbacks_list)\n",
        "  return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzmrdsAXlvMv"
      },
      "source": [
        "def load_weights(model, model_weights):\n",
        "  model.load_weights(model_weights)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqgDL69hlvJ6"
      },
      "source": [
        "def log_metrics(model, ds):\n",
        "  return model.evaluate(ds, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTSQ9Xk4dG86"
      },
      "source": [
        "def predictions(model, df, target_id, img_height=200,img_width=200):\n",
        "  data_list = []\n",
        "  imgs_path = '/content/img_path/' + target_id + '/imgs/'\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    img_path = os.path.join(imgs_path, row['img_path'])\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "    #img_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(img_batch)\n",
        "    prediction = model.predict(img_batch)\n",
        "    data_list.append((row['drug_id'],row['labels'],prediction[0][0]))\n",
        "\n",
        "  df = pd.DataFrame(data_list,columns=['drug_id','label','y_pred_prob',])  \n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNfzuZIGyMCV"
      },
      "source": [
        "def label_encoding_smiles(df):\n",
        "\n",
        "  CHARCANSMISET = { \"#\": 1, \"%\": 2, \")\": 3, \"(\": 4, \"+\": 5, \"-\": 6, \n",
        "         \".\": 7, \"1\": 8, \"0\": 9, \"3\": 10, \"2\": 11, \"5\": 12, \n",
        "         \"4\": 13, \"7\": 14, \"6\": 15, \"9\": 16, \"8\": 17, \"=\": 18, \n",
        "         \"A\": 19, \"C\": 20, \"B\": 21, \"E\": 22, \"D\": 23, \"G\": 24,\n",
        "         \"F\": 25, \"I\": 26, \"H\": 27, \"K\": 28, \"M\": 29, \"L\": 30, \n",
        "         \"O\": 31, \"N\": 32, \"P\": 33, \"S\": 34, \"R\": 35, \"U\": 36, \n",
        "         \"T\": 37, \"W\": 38, \"V\": 39, \"Y\": 40, \"[\": 41, \"Z\": 42, \n",
        "         \"]\": 43, \"_\": 44, \"a\": 45, \"c\": 46, \"b\": 47, \"e\": 48, \n",
        "         \"d\": 49, \"g\": 50, \"f\": 51, \"i\": 52, \"h\": 53, \"m\": 54, \n",
        "         \"l\": 55, \"o\": 56, \"n\": 57, \"s\": 58, \"r\": 59, \"u\": 60,\n",
        "         \"t\": 61, \"y\": 62, \"/\" : 63, \"\\\\\" : 64, \"@\":65}\n",
        "\n",
        "  CHARCANSMILEN = 65\n",
        "\n",
        "  def one_hot_sequence(line, MAX_SEQ_LEN = 80, smi_ch_ind = CHARCANSMISET):\n",
        "    X = np.zeros((MAX_SEQ_LEN, len(smi_ch_ind))) \n",
        "    for i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
        "        X[i,(smi_ch_ind[ch])-1] = 1\n",
        "\n",
        "    return X.flatten() #.tolist()\n",
        "\n",
        "  df['lbl_encoding'] = df.apply(\n",
        "      lambda row : one_hot_sequence(row['canonical_smiles']), axis = 1)\n",
        "\n",
        "  return df\n",
        "\n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KFqJxgcfy14"
      },
      "source": [
        "def prepare_svm_data(df, cnn_predict_df,meta_learning=False):\n",
        "\n",
        "  df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "  def f(row):\n",
        "    if row['y_pred_prob'] <= 0.5 :\n",
        "        val = 0\n",
        "    else:\n",
        "        val = 1\n",
        "    return val\n",
        "\n",
        "  def svm_cnn_date(df, cnn_predict_df):\n",
        "    cnn_predict_df['y_pred'] = cnn_predict_df.apply(f,axis=1)\n",
        "    return pd.merge(df, cnn_predict_df, left_on=['drug_id',], \n",
        "                          right_on=['drug_id'],how='inner')\n",
        "    \n",
        "  if meta_learning:\n",
        "    final_svm_df = svm_cnn_date(df, cnn_predict_df)\n",
        "    final_svm_df = pd.concat([pd.DataFrame(final_svm_df.lbl_encoding.values.tolist()), final_svm_df.y_pred, final_svm_df.labels],axis=1)\n",
        "  else:\n",
        "    final_svm_df = pd.concat([pd.DataFrame(df.lbl_encoding.values.tolist()), df.labels],axis=1)\n",
        "  \n",
        "  final_svm_df = final_svm_df.astype('uint8')\n",
        "\n",
        "  return final_svm_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZg7yL_pyL9Y"
      },
      "source": [
        "def train_svm(svm_df, kernel_type = 'rbf'):\n",
        "  X_train = svm_df.drop(\"labels\", axis = 1)\n",
        "  y_train = svm_df['labels']\n",
        "\n",
        "  model = SVC(kernel=kernel_type, probability=True)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3whGJIewyL6c"
      },
      "source": [
        "def test_svm(model, svm_df_test, metrics):\n",
        "  X_test = svm_df_test.drop(\"labels\", axis = 1)\n",
        "  y_test = svm_df_test['labels']\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  if 'accuracy' in metrics:\n",
        "    return round(accuracy_score(y_test,y_pred),2)\n",
        "  else:\n",
        "    roc_auc = round(roc_auc_score(y_test,y_pred),2) \n",
        "    pred_f1_score = round(f1_score(y_test,y_pred),2)\n",
        "    return roc_auc, pred_f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0RHmbwuXUTO"
      },
      "source": [
        "### Preparing data and running model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxvOfVdoyL3U"
      },
      "source": [
        "src_df = prepare_data()\n",
        "# k = 100\n",
        "# min_range = 1000\n",
        "# max_range = 3000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PStR0iqGHsO"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIYAZCVaGFww"
      },
      "source": [
        "src_df['drug_id'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xWshuQ8GN7R"
      },
      "source": [
        "json_df = pd.read_csv('/content/drive/MyDrive/ML-DTI/json_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxz9doYxGN4m"
      },
      "source": [
        "json_df['drug_id'].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sExQUxLDGN1l"
      },
      "source": [
        "409288/409311"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7weAXkm9PlH"
      },
      "source": [
        "target_count_df = src_df['target_id'].value_counts().rename_axis('target_id').reset_index(name='counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anhfdXhR811T"
      },
      "source": [
        "#labels = [0,1,2,3,4,5,6,7,8,9]\n",
        "target_count_df['counts_bins'] = pd.cut(target_count_df['counts'], bins=[0,500,1000,3000,10000,40000], \n",
        "             include_lowest=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRXOPGOv94Fs"
      },
      "source": [
        "target_count_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ2cZplo97eV"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrRpOBqeC1zv"
      },
      "source": [
        "!pip install seaborn --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPYbIRim_Cpb"
      },
      "source": [
        "sns.set(rc={'figure.figsize':(11.7,8.27)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbk1nqE5-GE2"
      },
      "source": [
        "sns.countplot(x='counts_bins', data=target_count_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M64rgStYD8Si"
      },
      "source": [
        "ax = sns.countplot(x=\"counts_bins\", data=target_count_df)\n",
        "\n",
        "for p in ax.patches:\n",
        "   ax.annotate(p.get_height(), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "\n",
        "ax.set_title(\"Compound count per category\")\n",
        "ax.set_xlabel('compounds count bins')\n",
        "plt.show(ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KztAujqbfPW"
      },
      "source": [
        "### Class comparison for all data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qHdlzojZG1H"
      },
      "source": [
        "#agg_df = src_df.groupby(['target_id','labels'])['drug_id'].count().rename_axis(['target_id','labels']).reset_index(name='counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l21NGWSvZTaO"
      },
      "source": [
        "#agg_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFFU_cp6qFA8"
      },
      "source": [
        "#sns.lineplot(x=agg_df.index,y='counts',hue='labels',hue_norm=(0,1),data=agg_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vQCPO7JrDBR"
      },
      "source": [
        "agg_df = src_df.groupby(['target_id'])['labels'].value_counts(normalize=True).mul(100).rename('percent').reset_index()\n",
        "#.pipe((sns.lineplot,'data'), x=agg_df.index/2,y='percent',hue='labels',))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5BFRMC9rvaV"
      },
      "source": [
        "agg_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGP7pJzDvTWx"
      },
      "source": [
        "#cgfc_df.plot(x=\"id\", y=[\"action\", \"comedy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRVhM43_sBUQ"
      },
      "source": [
        "#sns.lineplot(x=range(0,812),y='percent',hue='labels',data=cgfc_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqoaXTdGJEVZ"
      },
      "source": [
        "x = agg_df.pivot(index='target_id',columns='labels',values='percent').reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-idYq0XZUrsY"
      },
      "source": [
        "x.columns.name = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWD533CiRbcA"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0oKhhFQf2iv"
      },
      "source": [
        "x = x.assign(id=x.groupby(['target_id',]).ngroup())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXAcUGeHJER3"
      },
      "source": [
        "x['diff'] = abs(x[0] - x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KxGVrmGSZcO"
      },
      "source": [
        "x.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKBDvv7qUKf7"
      },
      "source": [
        "(x['diff'] > 20).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A5Pp8MmV0SX"
      },
      "source": [
        "(x['diff'] == 0).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RPgB21XgrPT"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUviUCNFgP5M"
      },
      "source": [
        "ax = x.plot(x=\"id\", y=[0, 1],figsize=(20,10))\n",
        "ax.set_ylabel('Percentage data distribution',fontsize = 12,position=(0.7, .5))\n",
        "ax.set_xlabel('Target proteins',fontsize = 12, )\n",
        "ax.set_title('Class comparison', fontsize = 20, position=(0.5, .95))\n",
        "plt.show(ax)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAjZBO29Uakv"
      },
      "source": [
        "#sns.set(rc={'figure.figsize':(11.7,8.27)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPTx6rWjSNTk"
      },
      "source": [
        "# ax = sns.scatterplot(y = 'diff', x = x.index, data = x)\n",
        "# ax.set_ylabel('Percentage difference')\n",
        "# ax.set_xlabel('Target proteins')\n",
        "# ax.set_title('Class comparison', fontsize = 20)\n",
        "# plt.show(ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfxtK9WKbVo-"
      },
      "source": [
        "### filtered record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8MF2ZPeO9K_"
      },
      "source": [
        "mask = src_df['target_id'].isin(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI-4A9VEZjR-"
      },
      "source": [
        "filtered_df = src_df.loc[mask].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRNkz_YdZ0h2"
      },
      "source": [
        "filtered_df['target_id'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSNCGRHBaH3r"
      },
      "source": [
        "agg_df = filtered_df.groupby(['target_id','labels'])['drug_id'].count().rename_axis(['target_id','labels']).reset_index(name='counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsWzZbaXaWi9"
      },
      "source": [
        "agg_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t5jQJE8aPRP"
      },
      "source": [
        "pivot_df = agg_df.pivot(index='target_id',columns='labels',values='counts').reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qu47-G6amrM"
      },
      "source": [
        "pivot_df.columns.name = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HTh1R8QaHz4"
      },
      "source": [
        "pivot_df['diff'] = abs(pivot_df[0]/(pivot_df[0] + pivot_df[1]) - pivot_df[1]/(pivot_df[0] + pivot_df[1])) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4uYqQZEaHgI"
      },
      "source": [
        "pivot_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y53RuRewvlFn"
      },
      "source": [
        "sns.lineplot(x=\"id\", y=[\"Percentage +ve\", \"Percentage -ve\"], data = pivot_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXlMg4GveqZ1"
      },
      "source": [
        "pivot_df['Percentage +ve'] = (pivot_df[1]/(pivot_df[0] + pivot_df[1])) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD2njrTAe6Qj"
      },
      "source": [
        "pivot_df['Percentage -ve'] = (pivot_df[0]/(pivot_df[0] + pivot_df[1])) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr54xNo1nrhq"
      },
      "source": [
        "pivot_df = pivot_df.assign(id=pivot_df.groupby(['target_id',]).ngroup())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvwFSaFWa_K1"
      },
      "source": [
        "pivot_df['diff'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w6Yp6VnbEdg"
      },
      "source": [
        "(pivot_df['diff'] > 20).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRXS_ty3bIWF"
      },
      "source": [
        "(pivot_df['diff'] == 0).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2KAdwE2bOBs"
      },
      "source": [
        "sns.set(rc={'figure.figsize':(11.7,8.27)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rp38k4IbRQ2"
      },
      "source": [
        "ax = sns.scatterplot(y = 'diff', x = pivot_df.index, data = pivot_df)\n",
        "ax.set_ylabel('Percentage difference')\n",
        "ax.set_xlabel('Target proteins')\n",
        "ax.set_title('Class comparison', fontsize = 20)\n",
        "plt.show(ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv_rPNNSbROT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2pztvBubRLz"
      },
      "source": [
        "## SMILES EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqG0Myc9bRJG"
      },
      "source": [
        "src_df['smiles_length'] = src_df['canonical_smiles'].str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FIqCsPvE00m"
      },
      "source": [
        "src_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk8lVRlVE8JR"
      },
      "source": [
        "smiles_df = src_df[['drug_id','smiles_length']].drop_duplicates().reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnqEVJMCFJvY"
      },
      "source": [
        "smiles_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3bplJJNJXX0"
      },
      "source": [
        "smiles_df['smiles_length'].describe(percentiles=[.9,.92,.95])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jmiXrgcF44Q"
      },
      "source": [
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "ax = sns.boxplot(x=smiles_df[\"smiles_length\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa2tYmYYF43K"
      },
      "source": [
        "iqr = smiles_df['smiles_length'][smiles_df['smiles_length'].between(0, smiles_df['smiles_length'].quantile(.92), inclusive=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTDKLGEkF4x6"
      },
      "source": [
        "ax = sns.boxplot(iqr)\n",
        "ax.set_title('with 92% data', fontsize = 20, position=(0.88, .92))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk9-_JbrF4vN"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize = (20,10))\n",
        "# #plt1 = sns.boxplot(x=smiles_df[\"smiles_length\"])\n",
        "# plt2 = sns.boxplot(iqr)\n",
        "# ax[0].boxplot(x=smiles_df[\"smiles_length\"])\n",
        "# ax[1].plot(plt2)\n",
        "\n",
        "plt1 = sns.boxplot(  x=smiles_df[\"smiles_length\"],  orient='v' , ax=ax[0])\n",
        "plt2 = sns.boxplot(  x = iqr ,  orient='v', ax=ax[1])\n",
        "plt1.set_title('100% data', fontsize = 20, position=(0.85, .93))\n",
        "plt2.set_title('92% data', fontsize = 20, position=(0.85, .93))\n",
        "plt.show(plt1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJOgxVeWGLs7"
      },
      "source": [
        "## EDA ends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4yDorQ-XDKi"
      },
      "source": [
        "# target_count_df = src_df['target_id'].value_counts().rename_axis('Target_ID').reset_index(name='count')\n",
        "# full_target_ids = target_count_df[(target_count_df['count'] > min_range) & (target_count_df['count'] < max_range)]['Target_ID'].tolist()\n",
        "# target_ids = random.sample(full_target_ids, k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIhzixSkXDGs"
      },
      "source": [
        "l = ['CHEMBL223','CHEMBL3473','CHEMBL228','CHEMBL276','CHEMBL3568','CHEMBL1900','CHEMBL4822','CHEMBL1981','CHEMBL2069','CHEMBL3024','CHEMBL3231','CHEMBL2959','CHEMBL2742','CHEMBL1908389','CHEMBL4578','CHEMBL1785','CHEMBL1994','CHEMBL3286','CHEMBL4128','CHEMBL206','CHEMBL4308','CHEMBL257','CHEMBL2993','CHEMBL2039','CHEMBL2292','CHEMBL208','CHEMBL2581','CHEMBL1855','CHEMBL2028','CHEMBL6136','CHEMBL2413','CHEMBL3571','CHEMBL2722','CHEMBL2695','CHEMBL298','CHEMBL1821','CHEMBL213','CHEMBL2014','CHEMBL304','CHEMBL2001','CHEMBL3522','CHEMBL2949','CHEMBL1946','CHEMBL5147','CHEMBL3974','CHEMBL3920','CHEMBL1867','CHEMBL288','CHEMBL2016','CHEMBL3973','CHEMBL2598','CHEMBL3358','CHEMBL1835','CHEMBL1978','CHEMBL4588','CHEMBL216','CHEMBL2431','CHEMBL281','CHEMBL3553','CHEMBL1875','CHEMBL4204','CHEMBL2808','CHEMBL229','CHEMBL1936','CHEMBL331','CHEMBL3594','CHEMBL4794','CHEMBL2820','CHEMBL338','CHEMBL3045','CHEMBL2525','CHEMBL6164','CHEMBL3142','CHEMBL3649','CHEMBL5407','CHEMBL2035','CHEMBL1991','CHEMBL4908','CHEMBL2208','CHEMBL221','CHEMBL321','CHEMBL4422','CHEMBL3979','CHEMBL265','CHEMBL3976','CHEMBL3869','CHEMBL2047','CHEMBL335','CHEMBL2276','CHEMBL324','CHEMBL1801','CHEMBL231','CHEMBL308','CHEMBL3629','CHEMBL313']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWSKHUU6IqEy"
      },
      "source": [
        "l.index('CHEMBL2820')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPS5xcjAXONG"
      },
      "source": [
        "l[55]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ksQEb6QQjzv"
      },
      "source": [
        "target_ids = l[56:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W-4_PskixVk"
      },
      "source": [
        "len(target_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlyy0Phi0E7e"
      },
      "source": [
        "model_name = 'inception'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pfMdTeL_1TA"
      },
      "source": [
        "metrics = ['accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzrVd2RXQLA",
        "collapsed": true
      },
      "source": [
        "start_time = time.time()\n",
        "main(src_df, target_ids,model_name,metrics)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjGCE9xMQtAk"
      },
      "source": [
        "Hello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWsECJu_gt5V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}